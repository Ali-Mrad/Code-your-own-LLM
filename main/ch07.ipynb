{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Finetuning To Follow Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.1\n",
      "numpy version: 1.23.5\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.2.2\n",
      "tensorflow version: 2.16.2\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",  # Plotting library\n",
    "        \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "        \"tiktoken\",    # Tokenizer\n",
    "        \"torch\",       # Deep learning library\n",
    "        \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "        \"pandas\"       # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Preparing a dataset for supervised instruction finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adap the format of the data \n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 935\n",
      "Number of validation samples: 55\n",
      "Number of test samples: 110\n"
     ]
    }
   ],
   "source": [
    "# divide the dataset into a training, validation, and test set\n",
    "train_portion = int(len(data) * 0.85)  \n",
    "test_portion = int(len(data) * 0.1)   \n",
    "val_portion = len(data) - train_portion - test_portion  \n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_data))\n",
    "print(\"Number of validation samples:\", len(val_data))\n",
    "print(\"Number of test samples:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Organizing data into training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256,device =\"cpu\"):\n",
    "    # Find the longest sequence in the batch and increase the max length by +1, which will add one extra padding token below\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token \n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "    # Stack the inputs into a single tensor\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4, 50256],\n",
      "        [    5,     6, 50256, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256, 50256],\n",
      "        [   10,    11,    12,    13,    14,    15]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "inputs_4 = [10, 11, 12, 13, 14, 15]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3,\n",
    "    inputs_4\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(batch,pad_token_id=50256,device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets that why the extra padding token is needed\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4, 50256],\n",
      "        [    5,     6, 50256, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256, 50256],\n",
      "        [   10,    11,    12,    13,    14,    15]])\n",
      "tensor([[    1,     2,     3,     4, 50256, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256, 50256],\n",
      "        [   11,    12,    13,    14,    15, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
    "\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  \n",
    "\n",
    "        # Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id # mask of the same shape as targets and True for all padding tokens\n",
    "        indices = torch.nonzero(mask).squeeze() # indices of the padding tokens\n",
    "        if indices.numel() > 1: # if there are padding tokens\n",
    "            targets[indices[1:]] = ignore_index # replace all but the first padding token with ignore_index\n",
    "\n",
    "        # Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4, 50256],\n",
      "        [    5,     6, 50256, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256, 50256],\n",
      "        [   10,    11,    12,    13,    14,    15]])\n",
      "tensor([[    1,     2,     3,     4, 50256,  -100],\n",
      "        [    6, 50256,  -100,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100,  -100],\n",
      "        [   11,    12,    13,    14,    15, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    "     )\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  \n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)\n",
    "# we can see that the loss is the same as in loss_1, which is what we want -100 is ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Creating data loaders for an instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(custom_collate_fn,device=device,allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to gpt2-medium-355M.pth\n"
     ]
    }
   ],
   "source": [
    "file_name = \"gpt2-medium-355M.pth\"\n",
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded to {file_name}\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "model.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 Finetuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.825897216796875\n",
      "Validation loss: 3.7619214057922363\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.102\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.945\n",
      "Ep 1 (Step 000015): Train loss 0.856, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.753, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.798, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.790\n",
      "Ep 1 (Step 000050): Train loss 0.662, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.764\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.652, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.729\n",
      "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.709\n",
      "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
      "Ep 1 (Step 000095): Train loss 0.500, Val loss 0.681\n",
      "Ep 1 (Step 000100): Train loss 0.502, Val loss 0.677\n",
      "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.667\n",
      "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.672\n",
      "Ep 2 (Step 000125): Train loss 0.450, Val loss 0.687\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
      "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.681\n",
      "Ep 2 (Step 000140): Train loss 0.409, Val loss 0.681\n",
      "Ep 2 (Step 000145): Train loss 0.368, Val loss 0.681\n",
      "Ep 2 (Step 000150): Train loss 0.381, Val loss 0.676\n",
      "Ep 2 (Step 000155): Train loss 0.412, Val loss 0.676\n",
      "Ep 2 (Step 000160): Train loss 0.415, Val loss 0.684\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
      "Ep 2 (Step 000170): Train loss 0.323, Val loss 0.683\n",
      "Ep 2 (Step 000175): Train loss 0.336, Val loss 0.671\n",
      "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.658\n",
      "Ep 2 (Step 000185): Train loss 0.415, Val loss 0.660\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.651\n",
      "Ep 2 (Step 000195): Train loss 0.330, Val loss 0.638\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.638\n",
      "Ep 2 (Step 000205): Train loss 0.351, Val loss 0.634\n",
      "Ep 2 (Step 000210): Train loss 0.366, Val loss 0.632\n",
      "Ep 2 (Step 000215): Train loss 0.396, Val loss 0.636\n",
      "Ep 2 (Step 000220): Train loss 0.300, Val loss 0.648\n",
      "Ep 2 (Step 000225): Train loss 0.348, Val loss 0.661\n",
      "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.658\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 169.10 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 Extracting and saving responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(38705) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "100%|| 110/110 [38:30<00:00, 21.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(BASE_CONFIG)\n",
    "model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\", weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t = {\n",
    "        \"instruction\": \"list benefits of eating vegetables\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"He goes to the park every day.\"\n",
    "    }\n",
    "\n",
    "test_2 = {\n",
    "        \"instruction\": \" finish the sentence\",\n",
    "        \"input\": \"france is well known for its\",\n",
    "        \"output\": \"\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "list benefits of eating vegetables\n",
      "\n",
      "Model response:\n",
      ">> 1. They are rich in nutrients.\n",
      "2. They are low in calories.\n",
      "3. They are high in potassium.\n",
      "4. They are rich in fiber.\n",
      "5. They are low in sugar.\n",
      "6. They are rich in iron.\n",
      "7. They are rich in zinc.\n",
      "8. They are rich in manganese.\n",
      "9. They are rich in copper.\n",
      "10. They are rich in manganese dioxide.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_text = format_input(test_t)\n",
    "\n",
    "token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "print(input_text)\n",
    "#print(f\"\\nCorrect response:\\n>> {test_t['output']}\")\n",
    "print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      " finish the sentence\n",
      "\n",
      "### Input:\n",
      "france is well known for its\n",
      "\n",
      "Model response:\n",
      ">> beauty.\n",
      "\n",
      "\n",
      "france is known for its beauty.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_text = format_input(test_2)\n",
    "\n",
    "token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "print(input_text)\n",
    "#print(f\"\\nCorrect response:\\n>> {test_t['output']}\")\n",
    "print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3 = {\n",
    "        \"instruction\": \" Summarise the rules of chess in bullet-points.\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      " Summarise the rules of chess in bullet-points.\n",
      "\n",
      "Model response:\n",
      ">> ### Input:\n",
      "The game is played by placing the pieces on the board.\n",
      "\n",
      "\n",
      "The rules of chess are:\n",
      "1. The king must be in the center of the board.\n",
      "2. The queen must be on the opposite side of the board.\n",
      "3. The rook must be on the first square.\n",
      "4. The king must be on the square with the largest number of pieces.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_text = format_input(test_3)\n",
    "\n",
    "token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "print(input_text)\n",
    "#print(f\"\\nCorrect response:\\n>> {test_t['output']}\")\n",
    "print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_semester_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
